# FieldCopilot Portfolio Audit for Anthropic Product Engineer Role

**Date:** 2025-01-27  
**Auditor:** Applied AI Product Engineer Review  
**Repository:** FieldCopilot (Field Operations AI Assistant)

---

## 1. REPOSITORY OVERVIEW

### Tech Stack + Runtime

- **Language:** TypeScript (Node.js)
- **Frontend:** React 18 + TypeScript + Tailwind CSS + shadcn/ui + Vite
- **Backend:** Express.js + TypeScript
- **Database:** PostgreSQL + Drizzle ORM
- **AI/LLM:** OpenAI GPT-4o + text-embedding-3-small
- **Vector Search:** Custom cosine similarity (in-memory, not production-grade vector DB)
- **WebSocket:** `ws` library for voice agent
- **MCP/Tool Calling:** ‚ùå **NOT USING MCP** - Custom tool calling via structured JSON schema validation
- **Runtime:** Node.js (ES modules)

**Evidence:**
- `package.json`: Dependencies listed
- `server/lib/openai.ts`: Direct OpenAI SDK usage (not MCP)
- `server/lib/vectorstore.ts`: Custom cosine similarity implementation
- `server/routes.ts:525`: `validateWithRepair()` validates JSON schema (not MCP tool calls)

### Main User Workflow (End-to-End)

1. **Ingestion:** User uploads documents ‚Üí Job queued ‚Üí Async processing (extract ‚Üí chunk ‚Üí embed ‚Üí index)
2. **Chat:** User asks question ‚Üí RAG retrieval (top 5 chunks) ‚Üí LLM generates response with citations ‚Üí JSON validation + repair ‚Üí Response with citations
3. **Actions:** User requests action ‚Üí Policy check ‚Üí Approval (if required) ‚Üí Tool execution (Jira/Slack/Confluence) ‚Üí Audit log
4. **Playbooks:** User describes incident ‚Üí System generates structured playbook (SOP steps, PPE, shutdown, checklists, action drafts)
5. **Observability:** Admin views traces/spans/metrics in dashboard
6. **Evaluation:** Admin runs eval suite ‚Üí Metrics computed (Recall@K, Citation Integrity, etc.) ‚Üí CI gate checks for regressions

**Evidence:**
- `server/routes.ts:263-298`: `/api/ingest` endpoint
- `server/routes.ts:414-615`: `/api/chat` endpoint
- `server/routes.ts:654-789`: `/api/actions/execute` endpoint
- `server/routes.ts:1940-2074`: `/api/playbooks` endpoint

### Key Modules/Files (Top 10)

1. **`server/routes.ts`** (2559 lines) - All HTTP endpoints (chat, actions, playbooks, evals, observability)
2. **`server/storage.ts`** - Database operations (Drizzle ORM)
3. **`server/lib/jobs/runner.ts`** - Job queue worker with locking/concurrency/rate limiting
4. **`server/lib/jobs/handlers/ingestHandler.ts`** - Document ingestion with versioning
5. **`server/lib/vectorstore.ts`** - Vector search (cosine similarity)
6. **`server/lib/validation/jsonRepair.ts`** - JSON schema validation with LLM repair
7. **`server/lib/policy/checker.ts`** - Policy enforcement (role-based, tool constraints)
8. **`server/lib/observability/tracer.ts`** - Tracing infrastructure
9. **`shared/schema.ts`** - Database schema + Zod schemas
10. **`script/seed-evals.ts`** + `script/run-eval.ts` + `script/ci-gate.ts`** - Evaluation framework

### How to Run Locally

**Exact Commands:**

```bash
# 1. Install dependencies
npm install

# 2. Set up environment variables (.env)
DATABASE_URL=postgresql://user:password@localhost:5432/fieldcopilot
OPENAI_API_KEY=sk-...
# OAuth secrets (optional)
GOOGLE_CLIENT_ID=...
GOOGLE_CLIENT_SECRET=...
ATLASSIAN_CLIENT_ID=...
ATLASSIAN_CLIENT_SECRET=...
SLACK_CLIENT_ID=...
SLACK_CLIENT_SECRET=...

# 3. Push database schema
npm run db:push

# 4. Seed initial data
curl -X POST http://localhost:5000/api/seed
npm run seed:evals

# 5. Start server (dev mode)
npm run dev
# App available at http://localhost:5000

# 6. Start worker (separate terminal)
npm run worker

# 7. Run evaluations
npm run eval "Basic QNA Suite"

# 8. Run CI gate
npm run ci
```

**Evidence:**
- `README.md`: Setup instructions
- `package.json`: Scripts defined

### CI/CD or Test Setup

**Status:** ‚ùå **NO CI/CD PIPELINE FOUND**

- No `.github/workflows/` directory
- No GitHub Actions, CircleCI, or other CI config
- No automated test suite (except voice agent E2E tests)
- CI gate script exists but not wired to CI: `script/ci-gate.ts`

**Evidence:**
- `glob_file_search` for `.github/**`: No results
- `script/ci-gate.ts`: Manual script (not CI-integrated)
- `script/test_voice_e2e.ts`: Voice agent E2E tests exist but not in CI

---

## 2. EVALUATION FRAMEWORK AUDIT

### A. Golden Dataset

**Status:** üü° **PARTIAL** (3/5)

**Evidence:**
- **File:** `script/seed-evals.ts`
- **Format:** JSON stored in `evalSuites.jsonText` column
- **Count:** ~20 cases across 3 suites:
  - "Basic QNA Suite": 5 cases
  - "Action Suite": 3 cases
  - "Citation Suite": 2 cases
- **Structure:** Each case has `id`, `type` (QNA/ACTION), `prompt`, `mustCite`, `expectedSourceIds`, `expectedTool`, `requiredFields`
- **Gap:** No labeled expected outputs (rubric labels) - only expected tool/fields, not expected answer text or citation targets
- **Gap:** No 50-200 case dataset - only ~20 cases

**File Paths:**
- `script/seed-evals.ts:5-94` - Seed data definition
- `shared/schema.ts:450-480` - `evalSuites` and `evalCases` schema

### B. Rubric

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No written rubric document found**
- Metrics are computed but rubric definitions are implicit in code
- No explicit definitions of "faithfulness", "schema validity", "action success", "refusal quality"

**File Paths:**
- `server/routes.ts:2250-2558` - `runEvalCases()` function computes metrics but no rubric doc
- No `RUBRIC.md` or `EVAL_RUBRIC.md` file found

### C. Metrics

**Status:** ‚úÖ **PASS** (5/5)

**Evidence:**
- **RAG Metrics:**
  - Recall@K: `server/routes.ts:2344-2347`
  - Citation Integrity: `server/routes.ts:2365-2383`
  - Unsupported Claim Rate: `server/routes.ts:2386-2395`
- **Action Metrics:**
  - Tool Selection Accuracy: `server/routes.ts:2428-2436`
  - Parameter Correctness: `server/routes.ts:2439-2450`
- **System Metrics:**
  - Latency: `server/routes.ts:2308, 2463`
  - Token Usage: `server/routes.ts:2312-2316, 2464`
- **Aggregation:** `server/routes.ts:2492-2517` - Computes averages
- **Storage:** `server/routes.ts:2519-2557` - Stored in `evalRuns.metricsJson`

**File Paths:**
- `server/routes.ts:2250-2558` - `runEvalCases()` function

### D. Eval Runner

**Status:** ‚úÖ **PASS** (5/5)

**Evidence:**
- **CLI Command:** `npm run eval "Basic QNA Suite"` (via `script/run-eval.ts`)
- **API Endpoint:** `POST /api/eval-suites/:id/run` (`server/routes.ts:1796-1850`)
- **Report Format:** JSON stored in `evalRuns.resultsJson` and `evalRuns.metricsJson`
- **Report Structure:**
  - `summaryJson`: `{total, passed, failed, errors, passRate}`
  - `metricsJson`: `{recallAtK, citationIntegrity, unsupportedClaimRate, toolSelectionAccuracy, parameterCorrectness, totalTokens, totalLatencyMs}`
  - `resultsJson`: Array of per-case results with `{id, type, prompt, passed, reason, ...metrics}`

**File Paths:**
- `script/run-eval.ts` - CLI runner (creates run, but actual execution via API)
- `server/routes.ts:1796-1850` - API endpoint
- `server/routes.ts:2250-2558` - `runEvalCases()` execution logic

### E. Regression Diffs

**Status:** üü° **PARTIAL** (2/5)

**Evidence:**
- **Baseline Support:** `evalSuites.isBaseline` flag exists (`shared/schema.ts:450`)
- **CI Gate Script:** `script/ci-gate.ts` compares baseline vs current run
- **Diff Logic:** `script/ci-gate.ts:64-102` - Compares TSR, unsupported claim rate, cost-per-success
- **Gap:** No diff endpoint (`GET /api/eval-runs/:id/diff`)
- **Gap:** No diff report format (only console output)
- **Gap:** No UI for viewing diffs

**File Paths:**
- `script/ci-gate.ts:12-117` - Regression check logic
- `shared/schema.ts:450` - `isBaseline` field

### F. Release Gates

**Status:** üü° **PARTIAL** (2/5)

**Evidence:**
- **CI Gate Script:** `script/ci-gate.ts` exists with thresholds:
  - TSR drop > 3% ‚Üí fail
  - Unsupported claim rate rise > 2% ‚Üí fail
  - Cost-per-success rise > 10% without TSR improvement ‚Üí fail
- **Exit Code:** Returns non-zero on failure (`script/ci-gate.ts:107`)
- **Gap:** Not integrated into CI/CD (no GitHub Actions, etc.)
- **Gap:** No merge-blocking mechanism

**File Paths:**
- `script/ci-gate.ts:64-107` - Threshold checks

---

## 3. RELIABILITY + SAFETY AUDIT

### Prompt Injection Defenses

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No sanitization found** for external content (Jira/Confluence/Slack)
- **No prompt injection defenses** in:
  - `server/lib/sync/jiraSync.ts` - Fetches Jira content directly into context
  - `server/lib/sync/confluenceSync.ts` - Fetches Confluence HTML ‚Üí text (no sanitization)
  - `server/lib/sync/slackSync.ts` - Fetches Slack messages directly
  - `server/routes.ts:468-473` - Chunks inserted directly into prompt without sanitization
- **Gap:** No input validation/sanitization for user messages in chat endpoint
- **Gap:** No prompt injection detection or mitigation

**File Paths:**
- `server/lib/sync/jiraSync.ts:98-214` - Content fetching
- `server/lib/sync/confluenceSync.ts:73-100` - Content fetching
- `server/lib/sync/slackSync.ts:62-100` - Content fetching
- `server/routes.ts:468-499` - Prompt construction

### PII Handling/Redaction/Logging Policy

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No PII redaction found:**
  - `server/lib/sync/slackSync.ts` - Fetches user names/real names, no redaction
  - `server/lib/sync/jiraSync.ts` - Fetches assignee/reporter names, no redaction
  - `server/routes.ts:595` - Audit events store full prompts/responses (may contain PII)
- **No PII detection or masking**
- **No logging policy document**
- **Gap:** Audit events may contain sensitive data

**File Paths:**
- `server/lib/sync/slackSync.ts:89-91` - User name fetching
- `server/lib/sync/jiraSync.ts:13-14` - Assignee/reporter fields
- `server/routes.ts:595-615` - Audit event creation

### Tool-Call Schema Validation + Retry/Backoff + Idempotency

**Status:** ‚úÖ **PASS** (5/5)

**Evidence:**
- **Schema Validation:** `server/lib/validation/jsonRepair.ts:12-79` - `validateWithRepair()` with Zod schema + LLM repair
- **Retry/Backoff:** `server/lib/jobs/runner.ts:36-53` - `shouldRetry()` with exponential backoff
- **Idempotency:** 
  - `server/routes.ts:669-674` - Idempotency key check for approvals
  - `server/lib/jobs/handlers/ingestHandler.ts:74-88` - Content hash check for duplicate ingestion
  - `server/routes.ts:76` - Job idempotency key

**File Paths:**
- `server/lib/validation/jsonRepair.ts` - Validation + repair
- `server/lib/jobs/runner.ts:36-53, 240-283` - Retry logic
- `server/routes.ts:669-674` - Idempotency check

### Monitoring/Telemetry and Error Taxonomy

**Status:** ‚úÖ **PASS** (4/5)

**Evidence:**
- **Tracing:** `server/lib/observability/tracer.ts` - Comprehensive tracing with spans
- **Metrics Endpoint:** `server/routes.ts:1699-1745` - `/api/admin/observability/metrics`
- **Error Tracking:** Spans include `error` and `errorCode` fields
- **Gap:** No structured error taxonomy (no error code enum/constants)

**File Paths:**
- `server/lib/observability/tracer.ts` - Tracer implementation
- `server/routes.ts:1699-1745` - Metrics endpoint
- `shared/schema.ts:620-640` - `spans` table schema (error fields)

### Human-in-the-Loop Approvals

**Status:** ‚úÖ **PASS** (4/5)

**Evidence:**
- **Policy Check:** `server/lib/policy/checker.ts:109-114` - `requiresApproval` flag
- **Approval Storage:** `server/routes.ts:768-777` - `storage.createApproval()`
- **Gap:** No UI for approval workflow (no "pending approvals" page)
- **Gap:** No notification system for approvals

**File Paths:**
- `server/lib/policy/checker.ts:109-114` - Approval requirement logic
- `server/routes.ts:768-777` - Approval creation
- `shared/schema.ts:700-720` - `approvals` table schema

---

## 4. CUSTOMER-FACING PACKAGING AUDIT

### Digital Native Onboarding Playbook

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No onboarding playbook document found**
- **No discovery checklist**
- **No reference architectures document**
- **No 2-week pilot plan**

**File Paths:**
- No `ONBOARDING.md`, `PLAYBOOK.md`, or similar files found
- `PHASE0_DISCOVERY.md` exists but is internal technical discovery, not customer-facing

### Example Workshop Materials

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No workshop slides outline**
- **No workshop scripts**
- **No code snippets for workshops**

**File Paths:**
- No `WORKSHOP.md`, `WORKSHOP_SLIDES.md`, or similar files found

### Clear Examples/Templates

**Status:** üü° **PARTIAL** (2/5)

**Evidence:**
- **Playbooks Feature:** `client/src/pages/playbooks/` - UI exists for creating playbooks
- **API Examples:** `README.md` has some API endpoint documentation
- **Gap:** No customer-facing templates (e.g., "How to set up Jira integration")
- **Gap:** No example playbooks or use cases

**File Paths:**
- `client/src/pages/playbooks/new.tsx` - Playbook creation UI
- `README.md:207-238` - API endpoints (basic docs)

---

## 5. ENGINEERING QUALITY AUDIT

### Clean Architecture

**Status:** ‚úÖ **PASS** (4/5)

**Evidence:**
- **Separation of Concerns:**
  - `server/routes.ts` - HTTP layer
  - `server/storage.ts` - Data access layer
  - `server/lib/` - Business logic (jobs, validation, policy, sync)
- **Modular Structure:** Clear separation between handlers, sync engines, validation
- **Gap:** Some large files (`server/routes.ts` is 2559 lines)

**File Paths:**
- `server/` directory structure
- `server/lib/` subdirectories

### Reproducibility

**Status:** ‚úÖ **PASS** (4/5)

**Evidence:**
- **Database Migrations:** `migrations/0000_gigantic_frank_castle.sql` - Drizzle migrations
- **Seed Scripts:** `script/seed-evals.ts` - Reproducible eval data
- **Environment Variables:** `ENV_EXAMPLE_CONTENT.txt` - Example env vars
- **Gap:** No Docker setup for local development
- **Gap:** No `requirements.txt` equivalent (relies on `package.json` only)

**File Paths:**
- `migrations/` directory
- `script/seed-evals.ts`
- `ENV_EXAMPLE_CONTENT.txt`

### CI/CD

**Status:** ‚ùå **FAIL** (0/5)

**Evidence:**
- **No CI/CD pipeline found**
- **No automated tests in CI**
- **No deployment automation**

**File Paths:**
- No `.github/workflows/` directory
- No CI config files

---

## 6. SCORECARD

| Category | Score | Notes |
|----------|-------|-------|
| **Agentic/Tools** | **2/5** | Custom tool calling (not MCP), structured JSON validation, but no MCP integration |
| **Evals** | **3/5** | Metrics computed, eval runner exists, but no rubric doc, limited dataset (~20 cases), no diff UI |
| **Safety/Reliability** | **2/5** | Schema validation + retry/backoff/idempotency good, but no prompt injection defenses, no PII handling |
| **Packaging** | **1/5** | Playbooks feature exists, but no onboarding playbook, no workshop materials, limited examples |
| **Engineering Quality** | **3/5** | Clean architecture, reproducibility good, but no CI/CD, large files |

**Overall Score: 2.2/5** (Below portfolio-ready threshold)

---

## 7. EVIDENCE TABLE

| Requirement | Status | File Paths |
|-------------|--------|------------|
| **A. Golden Dataset (50-200 cases)** | PARTIAL | `script/seed-evals.ts:5-94` - Only ~20 cases, no labeled outputs |
| **B. Written Rubric** | FAIL | Missing - No rubric document found |
| **C. Metrics Computation** | PASS | `server/routes.ts:2250-2558` - All metrics computed |
| **D. Eval Runner (CLI/API)** | PASS | `script/run-eval.ts`, `server/routes.ts:1796-1850` |
| **E. Regression Diffs** | PARTIAL | `script/ci-gate.ts:64-102` - Logic exists, no endpoint/UI |
| **F. Release Gates (CI)** | PARTIAL | `script/ci-gate.ts` - Script exists, not in CI |
| **Prompt Injection Defenses** | FAIL | Missing - No sanitization in `server/lib/sync/*.ts`, `server/routes.ts:468-499` |
| **PII Handling** | FAIL | Missing - No redaction in sync handlers, audit events |
| **Tool Schema Validation** | PASS | `server/lib/validation/jsonRepair.ts:12-79` |
| **Retry/Backoff** | PASS | `server/lib/jobs/runner.ts:36-53, 240-283` |
| **Idempotency** | PASS | `server/routes.ts:669-674`, `server/lib/jobs/handlers/ingestHandler.ts:74-88` |
| **Monitoring/Telemetry** | PASS | `server/lib/observability/tracer.ts`, `server/routes.ts:1699-1745` |
| **Error Taxonomy** | PARTIAL | Spans have error fields, but no structured taxonomy |
| **Human-in-the-Loop** | PARTIAL | `server/lib/policy/checker.ts:109-114` - Logic exists, no UI |
| **Onboarding Playbook** | FAIL | Missing - No customer-facing onboarding docs |
| **Workshop Materials** | FAIL | Missing - No workshop slides/scripts |
| **Examples/Templates** | PARTIAL | `client/src/pages/playbooks/` - UI exists, no templates |
| **Clean Architecture** | PASS | `server/` structure is well-organized |
| **Reproducibility** | PASS | `migrations/`, `script/seed-evals.ts` |
| **CI/CD** | FAIL | Missing - No CI pipeline |

---

## 8. TOP 10 GAPS (Ranked by Importance for Anthropic Hiring)

1. **No MCP/Tool Calling Integration** - Using custom JSON schema validation instead of MCP protocol (critical for Anthropic role)
2. **No Prompt Injection Defenses** - External content (Jira/Confluence/Slack) inserted directly into prompts without sanitization
3. **No Evaluation Rubric Document** - Metrics computed but no written rubric defining quality criteria
4. **No CI/CD Pipeline** - No automated testing/deployment, CI gate script not integrated
5. **Limited Evaluation Dataset** - Only ~20 cases, need 50-200 with labeled expected outputs
6. **No PII Handling/Redaction** - User names, emails, etc. stored in audit logs and synced content without redaction
7. **No Customer-Facing Onboarding Playbook** - Missing "Digital Native onboarding playbook" style documentation
8. **No Regression Diff UI/Endpoint** - Diff logic exists in script but no API endpoint or UI
9. **No Workshop Materials** - Missing slides, scripts, code snippets for customer workshops
10. **No Approval Workflow UI** - Policy check creates approvals but no UI for reviewing/approving

---

## 9. UPGRADE PLAN

### Quick Wins (‚â§2 hours each)

1. **Add Evaluation Rubric Document** (1 hour)
   - Create `EVAL_RUBRIC.md` defining faithfulness, schema validity, action success, refusal quality
   - File: `Field-Copilot-1/EVAL_RUBRIC.md`

2. **Add Prompt Injection Sanitization** (2 hours)
   - Create `server/lib/safety/sanitize.ts` with function to escape/sanitize external content
   - Apply to `server/lib/sync/jiraSync.ts`, `confluenceSync.ts`, `slackSync.ts`
   - Apply to `server/routes.ts:468-473` (chunk insertion)

3. **Add Regression Diff Endpoint** (1.5 hours)
   - Add `GET /api/eval-runs/:id/diff` endpoint in `server/routes.ts`
   - Reuse logic from `script/ci-gate.ts:64-102`

4. **Add PII Redaction Helper** (2 hours)
   - Create `server/lib/safety/redactPII.ts` with regex patterns for emails, phone numbers, SSNs
   - Apply to audit event creation in `server/routes.ts:595`
   - Apply to sync content in `server/lib/sync/slackSync.ts:89-91`

5. **Expand Evaluation Dataset** (2 hours)
   - Add 30-50 more cases to `script/seed-evals.ts`
   - Include labeled expected outputs (answer text, citation targets)

### Deep Improvements (1-3 days each)

1. **Integrate MCP Protocol** (3 days)
   - Replace custom JSON schema validation with MCP tool calling
   - Update `server/routes.ts:525` to use MCP
   - Update `server/lib/openai.ts` to support MCP format
   - Files: `server/lib/mcp/` (new), `server/routes.ts`, `server/lib/openai.ts`

2. **Build CI/CD Pipeline** (2 days)
   - Create `.github/workflows/ci.yml` with:
     - Type checking (`npm run check`)
     - Eval suite run (`npm run eval`)
     - CI gate check (`npm run ci`)
     - Block merges on failure
   - Files: `.github/workflows/ci.yml` (new)

3. **Build Evaluation Dashboard UI** (2 days)
   - Create `client/src/pages/admin/eval-suites.tsx` - List suites, create/edit cases
   - Create `client/src/pages/admin/eval-runs/[id].tsx` - View results with metrics breakdown
   - Add regression diff visualization
   - Files: `client/src/pages/admin/eval-suites.tsx` (new), `client/src/pages/admin/eval-runs/[id].tsx` (new)

4. **Create Customer Onboarding Playbook** (2 days)
   - Create `ONBOARDING_PLAYBOOK.md` with:
     - Discovery checklist (what to ask customers)
     - Reference architectures (common setups)
     - 2-week pilot plan (week 1: setup, week 2: usage)
   - Files: `ONBOARDING_PLAYBOOK.md` (new)

5. **Create Workshop Materials** (2 days)
   - Create `WORKSHOP_MATERIALS.md` with:
     - Slides outline (intro, demo, hands-on)
     - Workshop script (timing, talking points)
     - Code snippets for hands-on exercises
   - Files: `WORKSHOP_MATERIALS.md` (new)

---

## 10. SUGGESTED RESUME BULLETS

### Option 1: Engineering-Forward

- **Built production-grade agentic AI system** with custom tool calling, structured JSON validation with LLM repair, and policy-based access control for Jira/Slack/Confluence integrations
- **Designed and implemented evaluation framework** with 20+ test cases, automated metrics computation (Recall@K, Citation Integrity, Tool Selection Accuracy), and regression detection with CI gate thresholds
- **Architected job queue system** with PostgreSQL `FOR UPDATE SKIP LOCKED` for atomic claiming, per-connector concurrency limits, token bucket rate limiting, and exponential backoff retries
- **Implemented comprehensive observability** with distributed tracing (traces/spans), metrics aggregation, and admin dashboard for monitoring RAG retrieval, LLM calls, and tool executions
- **Built source versioning system** with immutable snapshots, active chunk filtering, and citation tracking (sourceVersionId + charStart/charEnd) to prevent chunk mixing across document versions

### Option 2: Customer/Advisor-Forward

- **Delivered enterprise AI assistant** for field operations teams with RAG-powered knowledge retrieval, incident response playbook generation, and integrated tool actions (Jira/Slack/Confluence) with human-in-the-loop approvals
- **Designed evaluation framework** to measure system quality (faithfulness, citation integrity, tool accuracy) and prevent regressions with automated CI gates, enabling data-driven improvements
- **Built customer-facing playbook feature** that generates structured incident response procedures (SOP steps, PPE checklists, shutdown procedures) from natural language descriptions with source citations
- **Implemented policy-based governance** with role-based tool access control, constraint validation (allowed projects/channels/spaces), and explainable denial reasons for compliance and safety
- **Created observability dashboard** for admins to monitor system health, trace request flows, and analyze retrieval quality (similarity scores, citation rates) to optimize RAG performance

---

## SUMMARY

**Overall Assessment:** The repository demonstrates **solid engineering fundamentals** (clean architecture, job queue system, observability) but is **missing critical portfolio requirements** for an Anthropic Product Engineer role:

- ‚ùå **No MCP integration** (using custom tool calling)
- ‚ùå **No prompt injection defenses** (critical safety gap)
- ‚ùå **No evaluation rubric** (metrics computed but not documented)
- ‚ùå **No CI/CD pipeline** (no automated testing/deployment)
- ‚ùå **Limited customer-facing packaging** (no onboarding playbook, workshop materials)

**Recommendation:** Complete the **5 quick wins** (especially evaluation rubric and prompt injection defenses) and **2-3 deep improvements** (MCP integration, CI/CD, evaluation dashboard) before using as a portfolio piece. The codebase shows strong technical skills but needs these additions to demonstrate production-grade safety, evaluation rigor, and customer readiness expected for the role.
